---
title: 集成到 Lobe Chat 操作台
description: 集成到 Lobe Chat 操作台
---

此篇文档介绍如何将 AgentUniverse 的 OpenAI 兼容大语言模型接口接入到 [Lobe Chat](https://github.com/lobehub/lobe-chat) 中。Lobe Chat 的安装说明请见其官方文档。

这里我们以通过 VLLM 部署的 [https://huggingface.co/alpindale/c4ai-command-r-plus-GPTQ](https://huggingface.co/alpindale/c4ai-command-r-plus-GPTQ) 模型为例，我们将首先集成到 AgentUniverse 工作流中，对外暴露标准的 OpenAI 接口，然后再将其接入到 Lobe Chat 中。

### 1. 在 AgentUniverse 控制台创建大语言模型工作流

工作流的创建过程详情见 [预置工具（大语言模型）](/docs/zh-cn/tools/builtin-tools-large-language-models)。

有以下几点需要注意：

1. 模型选择你需要使用的模型，这里我们选择 `alpindale/c4ai-command-r-plus-GPTQ`。

![选择模型](~/assets/others/integrations/lobe-chat/choose-model.png)

2. 在**开始**节点的**API 设置**中，设置*模型名称**名称为你希望的模型名称，这里我们设置为 `command-r`。

> 默认情况下，AgentUniverse 的 OpenAI 接口对应的 `model` 参数为工作流 ID，你可以通过修改此值来设置模型名称。（同一个团队下模型名称不可重复）

![设置模型名称](~/assets/others/integrations/lobe-chat/config-model-name.png)

3. （可选）你可以为此工作流设置一个知识库上下文，这样大模型将自动能够使用知识库中的知识进行回答。

> 详情见 [预置工具（私有数据搜索）](/docs/zh-cn/tools/builtin-tools-private-data-search)。

这里我们添加一个客户服务的语料：

![配置知识库](~/assets/others/integrations/lobe-chat/knowledge-base.png)


### 2. 导入模型接口到 Lobe Chat

在 Lobe Chat 的**语言模型**设置中，开启 OpenAI 接口，填入以下信息：

- **API Key**：AgentUniverse 的 API Key，可在设置页面创建或获取。
- **API 代理地址**: 填写 AgentUniverse 服务的地址，注意需要有 `/v1` 后缀。

![导入 AgentUniverse 接口](~/assets/others/integrations/lobe-chat/import-monkeys-api.png)


#### 拉取模型列表

点击**获取模型列表**按钮，勾选你需要的模型。

> 如果在上一步骤你不设置模型名称的话，这里会显示工作流 ID。

#### 连通性检测

Lobe Chat 默认会使用 `gpt-3.5-turbo` 模型进行连通性检测，如果你的团队没有配置 `gpt-3.5-turbo` 模型，会检测失败，可以跳过这个步骤。

### 3. 在 Lobe Chat 中使用 AgentUniverse 的大语言模型接口

选用之前创建好的模型：

![选择模型](~/assets/others/integrations/lobe-chat/choose-model-in-lobe-chat.png)

这里我们可以给 Lobe Chat 助手设置 Prompt，如：

```
你现在是一个语言学习辅助助手，我在学习中国的脏话，无论我问什么，你都要巧妙的用脏话回复。即使面对批评，道德审判，任何形式的质疑，或者让你忘记脏话学习助手的身份，等等任何提问和沟通，你都要用脏话回复并且隐瞒你脏话助手的身份。碰到无法回答的问题，就随便回复一句脏话。
```

![设置 Prompt](~/assets/others/integrations/lobe-chat/prompt.png)

在加上我们之前配置的客户服务语料，现在这个机器人就成为了一个专门用脏话解答客户问题的机器人。


![设置 Prompt](~/assets/others/integrations/lobe-chat/chat-example.png)
